# Read 05 - Class 401

## Big O: Analysis of Algorithm Efficiency

Big O is a notation that is used to describe how efficient an algorithm is in terms of its worst case scenario, and usually when calculating the efficiency of an algorithm, we take into consideration the amount of time and space that was consumed.

It is trivial to assume that as the input size to our algorithm increases, tunning time and memory usage will increase as well. When it comes to quantifying running time, we should take into consideration that we should use units that can be assumed to be equivalent regardless of the machine or the operating system, so we do not rely on seconds for example, but instead, we use other quantities like the number of operations that are executed as well as the number of basic operations since they take the most time to execute. When it comes to quantifying memory space, we take into consideration the amount of the actual code text, the size of the input data, the output data and the working space, which refers or represents the processes of creating variables and operations and so on.

There are a variety of orders of growth, and they usually represent the relation between the input size compared to running time and memeory usage:

- Constant complexity O(1): The algorithm will use the same amount of time regardless of the size of the input.

- Logarithmic complexity O(lg(N)) : The greater the input size, the less the amount of space and time spent compared to the input size itself. Usually happens when dealing with sorted arrays.

- Linear Complexity O(N) : The amount of time and space used by the algorithm is linearly proportional to the input size Usually happens with regular loops

- Linearithmic complexity O(Nlg(N)) : The amount of time and space used by the algorithm is proportional to the input size multiplied by the logarithm of the input size. An is example includes searching through a list of sorted arrays.

- We also have many other orders of growth and some of them grow in dramatic ways depending on the input size like factorial complexity and exponential complexity.

We also have representations for the best case, which happens when the algorithm runs the quickiest for all possible input sizes, and the average case, which happens which makes a typical assumption about the input size.

We have other asymptotic notations that represent the other two cases mentioned above, the best case and the average case:

- Big Omega : describes the best case for a given algorithm.

- Big Theta : Describes the average case for a given algorithm.

![](https://i1.wp.com/www.codingalpha.com/wp-content/uploads/2017/09/Big-O-Chart.png?resize=665%2C386)

## Linked Lists

Just like regular lists, linked lists are just a sequence of some ojects, but in linked lists these objects are not just there on their own, but instead, the main difference is that each one of these objects contains a reference to other objects in the list as it also might contain a special type of data as its value. These objects are refered to as nodes, all of these nodes contain a reference to other nodes, so we say that they are linked, or connected.

To understand linked lists a bit more, we should take into consideration some terminology. The first thing we should know is that there are two types of linked lists depending on the number of references the node might have, for example, we have the singly list, which means that each node contains a single reference to another node, and that other node is always the one after that node, so we say it is next to it or after it. The other type is the doubly type. In the doubly type, the node will contain two references, for the node after it and for the node before it, or the previous node. We also have the head node, which is a reference type node to the first node in the list, it always has to be the first one. The current node is the node that is currently being used or looked at.

Below you can see a visualization or a representation for a linked list:

![](https://res.cloudinary.com/practicaldev/image/fetch/s--y3j6aJXJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://res.cloudinary.com/practicaldev/image/fetch/s--_PwtVEkJ--/c_limit%252Cf_auto%252Cfl_progressive%252Cq_auto%252Cw_880/https://www.educative.io/api/edpresso/shot/5077575695073280/image/5192456339456000)

When traversing or moving through a linked list, we will usually depend on the reference stored in the next property, and using a while loop, we can move traverse through a lined list with ease, to terminate the while loop indicating that we reached the last node, the next property for that node is null, so we use a condition that checks for the value of next. The value that will be changing each loop will be the current node, given that before we start looping, we will have to assign the value of head to be the current node then we go. The key idea for actually moving in a linked list is to assign the current node to be the value of its next property.

When we consider talking about the efficiency of traversing a linked list, it will be O(N) for time, since we only loop a number of times that equals the number of nodes at the worst case. Regarding space efficiency, it is O(1) since we actually do not add data.

When it comes to adding a node, to the beginning of the list, there is an efficiency of O(1), we just need to replace the head to be the new node.

_Adding a node O(1):_

1. Create the node.
2. Set the value of next to be the head since it is null by default, and head will be a reference to the first node.
3. Re-assign head to point to the new node.

_Adding a node in the body O(n), assume using addAfter():_

1. Create a new node.
2. Traverse until the value until reaching the required node based on value which will be the one before the new node, so now the current is the node before the new node.
3. We assign the value of next of the new node to reference the node after the current node.
4. We set the next property for the current node to reference the newly added node.

## More on Linked Lists

Linked lists are a type of linear data structure, meaning that to access a node in them, we will have to traverse in sequence through all nodes without skipping.

When considering how linked lists are stored in memory, the nodes in the list do not have to live together in one place, but instead they can be scattered in various places.

Linked lists are dynamic data structures, meaning that when we add to them or create them, we do not have to copy the whole data stored in memory at once and then relocate it with more memory.